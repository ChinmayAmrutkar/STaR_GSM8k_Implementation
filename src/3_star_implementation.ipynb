{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2d1cde-fb45-4c9c-872b-c4fde24181a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EXPERIMENT 3: Self-Taught Reasoner (STaR) - CHECKPOINT RESUMABLE VERSION\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdc57e6-4273-4e56-bcdd-0692f0425839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 1: Install Dependencies ---\n",
    "!pip install transformers>=4.35.0 datasets>=2.14.0 accelerate>=0.24.0 torch>=2.0.0 tqdm matplotlib numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514a87d4-733e-4745-a8e5-0cd7655597e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA A100-SXM4-80GB\n",
      "GPU memory: 85.10 GB\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 2: Import Libraries ---\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988fcd19-7e5d-49ee-b89d-9fc45227365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please log in to Hugging Face...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234fe3fcdcf246fba3299c96acd71a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CELL 3: Hugging Face Login ---\n",
    "print(\"\\nPlease log in to Hugging Face...\")\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6726ae33-ae18-47d1-812b-9636b7e95385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STaR TRAINING CONFIGURATION (CHECKPOINT RESUMABLE)\n",
      "================================================================================\n",
      "Model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Training samples: Full\n",
      "Test samples: Full\n",
      "STaR iterations: 1\n",
      "Epochs per iteration: 2\n",
      "Effective batch size: 16\n",
      "Output: ./small_project/star\n",
      "Checkpoint dir: ./small_project/star/checkpoints\n",
      "Force restart: False\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: Configuration ---\n",
    "class Config:\n",
    "    # Model\n",
    "    MODEL_NAME = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "    \n",
    "    # Dataset - ADJUST THESE FOR FULL RUN\n",
    "    USE_SUBSET = False\n",
    "    TRAIN_SUBSET_SIZE = 500  # Increased for better training\n",
    "    TEST_SUBSET_SIZE = 100   # Increased for better evaluation\n",
    "    \n",
    "    # Output\n",
    "    OUTPUT_DIR = \"./small_project/star\"\n",
    "    CHECKPOINT_DIR = \"./small_project/star/checkpoints\"\n",
    "    STATE_FILE = \"./small_project/star/training_state.json\"\n",
    "    \n",
    "    # Training\n",
    "    NUM_EPOCHS = 2  # Epochs per STaR iteration\n",
    "    BATCH_SIZE = 4   # Increased for A100\n",
    "    GRADIENT_ACCUMULATION_STEPS = 4  # Adjusted for larger batch\n",
    "    LEARNING_RATE = 2e-5\n",
    "    MAX_LENGTH = 512\n",
    "    \n",
    "    # STaR\n",
    "    STAR_ITERATIONS = 1\n",
    "    \n",
    "    # Generation\n",
    "    GENERATION_MAX_NEW_TOKENS = 256\n",
    "    TEMPERATURE = 0.7\n",
    "    TOP_P = 0.9\n",
    "    \n",
    "    # Resume settings\n",
    "    FORCE_RESTART = False  # Set True to ignore checkpoints and start fresh\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [config.OUTPUT_DIR, config.CHECKPOINT_DIR]:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"STaR TRAINING CONFIGURATION (CHECKPOINT RESUMABLE)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Model: {config.MODEL_NAME}\")\n",
    "print(f\"Training samples: {config.TRAIN_SUBSET_SIZE if config.USE_SUBSET else 'Full'}\")\n",
    "print(f\"Test samples: {config.TEST_SUBSET_SIZE if config.USE_SUBSET else 'Full'}\")\n",
    "print(f\"STaR iterations: {config.STAR_ITERATIONS}\")\n",
    "print(f\"Epochs per iteration: {config.NUM_EPOCHS}\")\n",
    "print(f\"Effective batch size: {config.BATCH_SIZE * config.GRADIENT_ACCUMULATION_STEPS}\")\n",
    "print(f\"Output: {config.OUTPUT_DIR}\")\n",
    "print(f\"Checkpoint dir: {config.CHECKPOINT_DIR}\")\n",
    "print(f\"Force restart: {config.FORCE_RESTART}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa13a20b-ff0d-4dce-b97b-46608303a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 5: Helper Functions ---\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract numerical answer from text\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Try #### format\n",
    "    match = re.search(r'####\\s*(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)', text)\n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')\n",
    "    \n",
    "    # Try common patterns\n",
    "    patterns = [\n",
    "        r'answer is[:\\s]+(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)',\n",
    "        r'=\\s*(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)\\s*$',\n",
    "        r'total[:\\s]+(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).replace(',', '')\n",
    "    \n",
    "    # Last resort: last number\n",
    "    numbers = re.findall(r'-?\\d+(?:,\\d+)*(?:\\.\\d+)?', text)\n",
    "    if numbers:\n",
    "        return numbers[-1].replace(',', '')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_training_prompt(question, solution):\n",
    "    \"\"\"Create training prompt\"\"\"\n",
    "    clean_solution = solution.strip()\n",
    "    if '####' not in clean_solution:\n",
    "        answer = extract_answer(clean_solution)\n",
    "        if answer:\n",
    "            clean_solution = f\"{clean_solution}\\n#### {answer}\"\n",
    "    \n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step and provide the final answer after ####.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{clean_solution}<|eot_id|>\"\"\"\n",
    "\n",
    "def create_inference_prompt(question):\n",
    "    \"\"\"Create inference prompt\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step and provide the final answer after ####.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_rationalization_prompt(question, correct_answer):\n",
    "    \"\"\"Create prompt with answer hint for rationalization\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step. The correct answer is {correct_answer}. Explain the reasoning that leads to this answer and end with #### {correct_answer}.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def load_gsm8k_data():\n",
    "    \"\"\"Load GSM8K dataset\"\"\"\n",
    "    print(\"Loading GSM8K dataset...\")\n",
    "    dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "    \n",
    "    train_data = []\n",
    "    for item in tqdm(dataset[\"train\"], desc=\"Processing train\"):\n",
    "        answer = extract_answer(item[\"answer\"])\n",
    "        if answer:\n",
    "            train_data.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"solution\": item[\"answer\"],\n",
    "                \"answer\": answer\n",
    "            })\n",
    "    \n",
    "    test_data = []\n",
    "    for item in tqdm(dataset[\"test\"], desc=\"Processing test\"):\n",
    "        answer = extract_answer(item[\"answer\"])\n",
    "        if answer:\n",
    "            test_data.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"solution\": item[\"answer\"],\n",
    "                \"answer\": answer\n",
    "            })\n",
    "    \n",
    "    print(f\"Loaded {len(train_data)} train and {len(test_data)} test examples\")\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8393f1f2-229c-4e14-99dd-5e81beb38a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh training (no checkpoint found or force restart)\n",
      "\n",
      " Training State:\n",
      "  Last completed iteration: -1\n",
      "  Next iteration to run: 0\n",
      "  Completed iterations: []\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 5: Checkpoint Management System ---\n",
    "class CheckpointManager:\n",
    "    \"\"\"Manages training state and checkpoints for resumable training\"\"\"\n",
    "    \n",
    "    def __init__(self, state_file, checkpoint_dir):\n",
    "        self.state_file = state_file\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.state = self.load_state()\n",
    "    \n",
    "    def load_state(self):\n",
    "        \"\"\"Load training state from disk\"\"\"\n",
    "        if os.path.exists(self.state_file) and not config.FORCE_RESTART:\n",
    "            print(f\"Loading training state from {self.state_file}\")\n",
    "            with open(self.state_file, 'r') as f:\n",
    "                state = json.load(f)\n",
    "            print(f\"âœ“ Loaded state: Last completed iteration {state.get('last_completed_iteration', -1)}\")\n",
    "            return state\n",
    "        else:\n",
    "            print(\"Starting fresh training (no checkpoint found or force restart)\")\n",
    "            return {\n",
    "                \"last_completed_iteration\": -1,\n",
    "                \"completed_iterations\": [],\n",
    "                \"all_stats\": [],\n",
    "                \"all_accuracies\": [],\n",
    "                \"start_time\": datetime.now().isoformat(),\n",
    "                \"last_update\": datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    def save_state(self):\n",
    "        \"\"\"Save current training state\"\"\"\n",
    "        self.state[\"last_update\"] = datetime.now().isoformat()\n",
    "        with open(self.state_file, 'w') as f:\n",
    "            json.dump(self.state, f, indent=2)\n",
    "        print(f\"ðŸ’¾ State saved to {self.state_file}\")\n",
    "    \n",
    "    def mark_iteration_complete(self, iteration, stats, accuracy):\n",
    "        \"\"\"Mark an iteration as complete\"\"\"\n",
    "        self.state[\"last_completed_iteration\"] = iteration\n",
    "        if iteration not in self.state[\"completed_iterations\"]:\n",
    "            self.state[\"completed_iterations\"].append(iteration)\n",
    "        self.state[\"all_stats\"].append(stats)\n",
    "        self.state[\"all_accuracies\"].append({\"iteration\": iteration, \"accuracy\": accuracy})\n",
    "        self.save_state()\n",
    "    \n",
    "    def is_iteration_complete(self, iteration):\n",
    "        \"\"\"Check if an iteration is already complete\"\"\"\n",
    "        return iteration in self.state.get(\"completed_iterations\", [])\n",
    "    \n",
    "    def get_last_model_path(self):\n",
    "        \"\"\"Get path to the last trained model\"\"\"\n",
    "        last_iter = self.state.get(\"last_completed_iteration\", -1)\n",
    "        if last_iter >= 0:\n",
    "            model_path = f\"{self.checkpoint_dir}/iteration_{last_iter}/model\"\n",
    "            if os.path.exists(model_path):\n",
    "                return model_path\n",
    "        return None\n",
    "    \n",
    "    def get_next_iteration(self):\n",
    "        \"\"\"Get the next iteration to run\"\"\"\n",
    "        return self.state.get(\"last_completed_iteration\", -1) + 1\n",
    "\n",
    "# Initialize checkpoint manager\n",
    "checkpoint_manager = CheckpointManager(config.STATE_FILE, config.CHECKPOINT_DIR)\n",
    "\n",
    "print(f\"\\n Training State:\")\n",
    "print(f\"  Last completed iteration: {checkpoint_manager.state['last_completed_iteration']}\")\n",
    "print(f\"  Next iteration to run: {checkpoint_manager.get_next_iteration()}\")\n",
    "print(f\"  Completed iterations: {checkpoint_manager.state.get('completed_iterations', [])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231082e5-03ce-40c5-9b32-be88f4d4ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing tokenizer...\n",
      "Tokenizer ready\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 7: Initialize Tokenizer ---\n",
    "print(\"\\nInitializing tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(f\"Tokenizer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac57369-ba5f-4339-8f93-e80eb971b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 6: Helper Functions ---\n",
    "def extract_answer(text):\n",
    "    \"\"\"Extract numerical answer from text with multiple strategies\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Strategy 1: Find #### format\n",
    "    match = re.search(r'####\\s*(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)', text)\n",
    "    if match:\n",
    "        return match.group(1).replace(',', '')\n",
    "    \n",
    "    # Strategy 2: Common patterns\n",
    "    patterns = [\n",
    "        r'answer is[:\\s]+(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)',\n",
    "        r'=\\s*(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)\\s*$',\n",
    "        r'total[:\\s]+(-?\\d+(?:,\\d+)*(?:\\.\\d+)?)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).replace(',', '')\n",
    "    \n",
    "    # Strategy 3: Last number in text\n",
    "    numbers = re.findall(r'-?\\d+(?:,\\d+)*(?:\\.\\d+)?', text)\n",
    "    if numbers:\n",
    "        return numbers[-1].replace(',', '')\n",
    "    \n",
    "    return None\n",
    "\n",
    "def create_training_prompt(question, solution):\n",
    "    \"\"\"Create training prompt in chat format\"\"\"\n",
    "    clean_solution = solution.strip()\n",
    "    if '####' not in clean_solution:\n",
    "        answer = extract_answer(clean_solution)\n",
    "        if answer:\n",
    "            clean_solution = f\"{clean_solution}\\n#### {answer}\"\n",
    "    \n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step and provide the final answer after ####.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{clean_solution}<|eot_id|>\"\"\"\n",
    "\n",
    "def create_inference_prompt(question):\n",
    "    \"\"\"Create inference prompt (no answer)\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step and provide the final answer after ####.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_rationalization_prompt(question, correct_answer):\n",
    "    \"\"\"Create prompt with answer hint for rationalization\"\"\"\n",
    "    return f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Solve this math problem step by step. The correct answer is {correct_answer}. Explain the reasoning that leads to this answer and end with #### {correct_answer}.\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd6e349-b2f8-4e4a-a9bc-915b959c5d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached GSM8K dataset...\n",
      "âœ“ Loaded from cache: 7473 train, 1319 test\n",
      "\n",
      "â†’ Using full dataset: 7473 train, 1319 test\n",
      "Data splits saved\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 7: Load and Cache Dataset ---\n",
    "def load_and_cache_gsm8k():\n",
    "    \"\"\"Load GSM8K dataset and cache it locally\"\"\"\n",
    "    cache_file = f\"{config.OUTPUT_DIR}/gsm8k_cache.json\"\n",
    "    \n",
    "    if os.path.exists(cache_file) and not config.FORCE_RESTART:\n",
    "        print(\"Loading cached GSM8K dataset...\")\n",
    "        with open(cache_file, 'r') as f:\n",
    "            cached_data = json.load(f)\n",
    "        print(f\"âœ“ Loaded from cache: {len(cached_data['train'])} train, {len(cached_data['test'])} test\")\n",
    "        return cached_data['train'], cached_data['test']\n",
    "    \n",
    "    print(\"Downloading GSM8K dataset...\")\n",
    "    dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "    \n",
    "    train_data = []\n",
    "    for item in tqdm(dataset[\"train\"], desc=\"Processing train\"):\n",
    "        answer = extract_answer(item[\"answer\"])\n",
    "        if answer:\n",
    "            train_data.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"solution\": item[\"answer\"],\n",
    "                \"answer\": answer\n",
    "            })\n",
    "    \n",
    "    test_data = []\n",
    "    for item in tqdm(dataset[\"test\"], desc=\"Processing test\"):\n",
    "        answer = extract_answer(item[\"answer\"])\n",
    "        if answer:\n",
    "            test_data.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"solution\": item[\"answer\"],\n",
    "                \"answer\": answer\n",
    "            })\n",
    "    \n",
    "    # Cache the dataset\n",
    "    with open(cache_file, 'w') as f:\n",
    "        json.dump({\"train\": train_data, \"test\": test_data}, f)\n",
    "    \n",
    "    print(f\"Dataset cached to {cache_file}\")\n",
    "    print(f\"Loaded {len(train_data)} train and {len(test_data)} test examples\")\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Load data\n",
    "full_train_data, full_test_data = load_and_cache_gsm8k()\n",
    "\n",
    "if config.USE_SUBSET:\n",
    "    train_data = full_train_data[:config.TRAIN_SUBSET_SIZE]\n",
    "    test_data = full_test_data[:config.TEST_SUBSET_SIZE]\n",
    "    print(f\"\\nâ†’ Using subset: {len(train_data)} train, {len(test_data)} test\")\n",
    "else:\n",
    "    train_data = full_train_data\n",
    "    test_data = full_test_data\n",
    "    print(f\"\\nâ†’ Using full dataset: {len(train_data)} train, {len(test_data)} test\")\n",
    "\n",
    "# Save data splits\n",
    "with open(f\"{config.OUTPUT_DIR}/train_data.json\", \"w\") as f:\n",
    "    json.dump(train_data, f, indent=2)\n",
    "with open(f\"{config.OUTPUT_DIR}/test_data.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=2)\n",
    "print(f\"Data splits saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a2f84f-ce87-4bcb-8d56-603a6754f142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing tokenizer...\n",
      "Tokenizer ready\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 8: Initialize Tokenizer (Shared) ---\n",
    "print(\"\\nInitializing tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "print(f\"Tokenizer ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d75620c3-7b31-4003-be00-5b842e6d5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 9: Generation Function ---\n",
    "def generate_solution(model, tokenizer, question, use_hint=False, correct_answer=None):\n",
    "    \"\"\"Generate solution with or without hint\"\"\"\n",
    "    if use_hint and correct_answer:\n",
    "        prompt = create_rationalization_prompt(question, correct_answer)\n",
    "    else:\n",
    "        prompt = create_inference_prompt(question)\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=config.GENERATION_MAX_NEW_TOKENS,\n",
    "            do_sample=True,\n",
    "            temperature=config.TEMPERATURE,\n",
    "            top_p=config.TOP_P,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            repetition_penalty=1.1,\n",
    "        )\n",
    "    \n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract response\n",
    "    if \"<|start_header_id|>assistant<|end_header_id|>\" in full_text:\n",
    "        response = full_text.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1]\n",
    "        response = response.replace(\"<|eot_id|>\", \"\").strip()\n",
    "    else:\n",
    "        response = full_text[len(prompt):].strip()\n",
    "    \n",
    "    # Extract answer\n",
    "    predicted_answer = extract_answer(response)\n",
    "    \n",
    "    return response, predicted_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24eb5502-689b-412d-b0eb-6229a3ce9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 10: STaR Dataset Generation Function ---\n",
    "def generate_star_dataset(model, tokenizer, train_data, iteration):\n",
    "    \"\"\"\n",
    "    Generate STaR training dataset\n",
    "    Returns: star_data, stats\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STaR DATASET GENERATION - ITERATION {iteration}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Check if already generated\n",
    "    iter_dir = f\"{config.CHECKPOINT_DIR}/iteration_{iteration}\"\n",
    "    star_dataset_file = f\"{iter_dir}/star_dataset.json\"\n",
    "    stats_file = f\"{iter_dir}/generation_stats.json\"\n",
    "    \n",
    "    if os.path.exists(star_dataset_file) and os.path.exists(stats_file) and not config.FORCE_RESTART:\n",
    "        print(f\"Loading cached STaR dataset from {star_dataset_file}\")\n",
    "        with open(star_dataset_file, 'r') as f:\n",
    "            star_data = json.load(f)\n",
    "        with open(stats_file, 'r') as f:\n",
    "            stats = json.load(f)\n",
    "        print(f\"âœ“ Loaded {len(star_data)} examples from cache\")\n",
    "        return star_data, stats\n",
    "    \n",
    "    # Generate new dataset\n",
    "    os.makedirs(iter_dir, exist_ok=True)\n",
    "    \n",
    "    star_data = []\n",
    "    stats = {\n",
    "        \"total\": len(train_data),\n",
    "        \"correct_without_hint\": 0,\n",
    "        \"correct_with_hint\": 0,\n",
    "        \"failed\": 0,\n",
    "        \"iteration\": iteration\n",
    "    }\n",
    "    \n",
    "    detailed_log = []\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Generating rationales for {len(train_data)} examples...\")\n",
    "    \n",
    "    for idx, item in enumerate(tqdm(train_data, desc=f\"STaR Gen (Iter {iteration})\")):\n",
    "        question = item[\"question\"]\n",
    "        correct_answer = item[\"answer\"]\n",
    "        \n",
    "        # Step 1: Try without hint\n",
    "        response, predicted = generate_solution(model, tokenizer, question, use_hint=False)\n",
    "        \n",
    "        is_correct = False\n",
    "        if predicted and correct_answer:\n",
    "            try:\n",
    "                is_correct = abs(float(predicted) - float(correct_answer)) < 0.01\n",
    "            except:\n",
    "                is_correct = predicted == correct_answer\n",
    "        \n",
    "        if is_correct:\n",
    "            # Success! Add to dataset\n",
    "            stats[\"correct_without_hint\"] += 1\n",
    "            star_data.append({\n",
    "                \"text\": create_training_prompt(question, response),\n",
    "                \"question\": question,\n",
    "                \"answer\": correct_answer,\n",
    "                \"method\": \"generation\"\n",
    "            })\n",
    "            detailed_log.append({\n",
    "                \"index\": idx,\n",
    "                \"method\": \"generation\",\n",
    "                \"success\": True,\n",
    "                \"predicted\": predicted,\n",
    "                \"correct\": correct_answer\n",
    "            })\n",
    "        else:\n",
    "            # Step 2: Try with hint (rationalization)\n",
    "            hint_response, hint_predicted = generate_solution(\n",
    "                model, tokenizer, question, use_hint=True, correct_answer=correct_answer\n",
    "            )\n",
    "            \n",
    "            is_hint_correct = False\n",
    "            if hint_predicted and correct_answer:\n",
    "                try:\n",
    "                    is_hint_correct = abs(float(hint_predicted) - float(correct_answer)) < 0.01\n",
    "                except:\n",
    "                    is_hint_correct = hint_predicted == correct_answer\n",
    "            \n",
    "            if is_hint_correct:\n",
    "                stats[\"correct_with_hint\"] += 1\n",
    "                star_data.append({\n",
    "                    \"text\": create_training_prompt(question, hint_response),\n",
    "                    \"question\": question,\n",
    "                    \"answer\": correct_answer,\n",
    "                    \"method\": \"rationalization\"\n",
    "                })\n",
    "                detailed_log.append({\n",
    "                    \"index\": idx,\n",
    "                    \"method\": \"rationalization\",\n",
    "                    \"success\": True,\n",
    "                    \"predicted\": hint_predicted,\n",
    "                    \"correct\": correct_answer\n",
    "                })\n",
    "            else:\n",
    "                stats[\"failed\"] += 1\n",
    "                detailed_log.append({\n",
    "                    \"index\": idx,\n",
    "                    \"method\": \"failed\",\n",
    "                    \"success\": False,\n",
    "                    \"predicted\": hint_predicted,\n",
    "                    \"correct\": correct_answer\n",
    "                })\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = stats[\"total\"]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"GENERATION RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Generated without hint: {stats['correct_without_hint']} ({stats['correct_without_hint']/total*100:.1f}%)\")\n",
    "    print(f\"Rationalized with hint: {stats['correct_with_hint']} ({stats['correct_with_hint']/total*100:.1f}%)\")\n",
    "    print(f\"Failed: {stats['failed']} ({stats['failed']/total*100:.1f}%)\")\n",
    "    print(f\"â†’ Total dataset size: {len(star_data)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Save STaR dataset\n",
    "    with open(star_dataset_file, \"w\") as f:\n",
    "        json.dump(star_data, f, indent=2)\n",
    "    \n",
    "    with open(stats_file, \"w\") as f:\n",
    "        json.dump(stats, f, indent=2)\n",
    "    \n",
    "    with open(f\"{iter_dir}/detailed_generation_log.json\", \"w\") as f:\n",
    "        json.dump(detailed_log, f, indent=2)\n",
    "    \n",
    "    print(f\"STaR dataset saved to {iter_dir}/\")\n",
    "    \n",
    "    return star_data, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d7b127-e8a9-437b-8fc2-50f642ca93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 11: Training Function ---\n",
    "def train_on_star_dataset(model, tokenizer, star_data, iteration):\n",
    "    \"\"\"Train model on STaR-generated dataset\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRAINING ON STaR DATASET - ITERATION {iteration}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training examples: {len(star_data)}\")\n",
    "    \n",
    "    iter_dir = f\"{config.CHECKPOINT_DIR}/iteration_{iteration}\"\n",
    "    model_path = f\"{iter_dir}/model\"\n",
    "    \n",
    "    # Check if model already trained\n",
    "    if os.path.exists(model_path) and not config.FORCE_RESTART:\n",
    "        print(f\"Model already trained for iteration {iteration}, loading from {model_path}\")\n",
    "        trained_model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "            use_cache=False\n",
    "        )\n",
    "        trained_model.gradient_checkpointing_enable()\n",
    "        return trained_model\n",
    "    \n",
    "    # Prepare dataset\n",
    "    dataset = Dataset.from_list(star_data)\n",
    "    \n",
    "    def tokenize_function(examples):\n",
    "        result = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=config.MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=None,\n",
    "        )\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "    \n",
    "    tokenized = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=dataset.column_names,\n",
    "        desc=\"Tokenizing\"\n",
    "    )\n",
    "    \n",
    "    # Training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{iter_dir}/checkpoints\",\n",
    "        num_train_epochs=config.NUM_EPOCHS,\n",
    "        per_device_train_batch_size=config.BATCH_SIZE,\n",
    "        gradient_accumulation_steps=config.GRADIENT_ACCUMULATION_STEPS,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        weight_decay=0.01,\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        fp16=not torch.cuda.is_bf16_supported(),\n",
    "        logging_steps=10,\n",
    "        logging_dir=f\"{iter_dir}/logs\",\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\",\n",
    "        max_grad_norm=1.0,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        dataloader_num_workers=4,  # Speed up data loading\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    \n",
    "    print(f\"Starting training...\")\n",
    "    train_result = trainer.train()\n",
    "    \n",
    "    print(f\"\\nTraining complete - Loss: {train_result.training_loss:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    trainer.save_model(model_path)\n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(f\"{iter_dir}/training_metrics.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"training_loss\": train_result.training_loss,\n",
    "            \"train_runtime\": train_result.metrics[\"train_runtime\"],\n",
    "            \"total_steps\": train_result.global_step,\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2058b0-a04b-4dbb-950a-88b5d43ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 12: Evaluation Function ---\n",
    "def evaluate_model(model, tokenizer, test_data, iteration_name=\"\"):\n",
    "    \"\"\"Evaluate model and save results\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"EVALUATING MODEL {iteration_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    results_log = []\n",
    "    \n",
    "    for idx, item in enumerate(tqdm(test_data, desc=\"Evaluating\")):\n",
    "        question = item[\"question\"]\n",
    "        correct_answer = item[\"answer\"]\n",
    "        \n",
    "        response, predicted = generate_solution(model, tokenizer, question)\n",
    "        \n",
    "        is_correct = False\n",
    "        if predicted and correct_answer:\n",
    "            try:\n",
    "                is_correct = abs(float(predicted) - float(correct_answer)) < 0.01\n",
    "            except:\n",
    "                is_correct = predicted == correct_answer\n",
    "        \n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        results_log.append({\n",
    "            \"index\": idx,\n",
    "            \"question\": question,\n",
    "            \"predicted_answer\": predicted,\n",
    "            \"correct_answer\": correct_answer,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"full_response\": response,\n",
    "            \"response_preview\": response[:200]\n",
    "        })\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return accuracy, results_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c5e9d47-80ee-4b99-8b6f-2022672b0b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING/RESUMING STaR TRAINING\n",
      "================================================================================\n",
      "Start/Resume time: 2025-10-12 18:26:53\n",
      "\n",
      "Starting from iteration 0\n",
      "Loading base model: meta-llama/Llama-3.2-3B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ffdf946ee0469fbc8cf9abe35d6d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and ready\n",
      "\n",
      "################################################################################\n",
      "# STaR ITERATION 1/1\n",
      "################################################################################\n",
      "Time: 2025-10-12 18:27:12\n",
      "\n",
      "================================================================================\n",
      "STaR DATASET GENERATION - ITERATION 0\n",
      "================================================================================\n",
      "Loading cached STaR dataset from ./small_project/star/checkpoints/iteration_0/star_dataset.json\n",
      "âœ“ Loaded 6407 examples from cache\n",
      "\n",
      "================================================================================\n",
      "TRAINING ON STaR DATASET - ITERATION 0\n",
      "================================================================================\n",
      "Training examples: 6407\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799a688cd19d443a9b106509606cd897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing:   0%|          | 0/6407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3953460/1355841579.py:69: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='802' max='802' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [802/802 21:49, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.167600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.371600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.324300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.333200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.336400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.318100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.308300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.295700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.304200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.292400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.303100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.302900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.245100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.241900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.251500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.255200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.246500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.248200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.246800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.249800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.253100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.254600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.253900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete - Loss: 0.3619\n",
      "Model saved to ./small_project/star/checkpoints/iteration_0/model\n",
      "\n",
      "================================================================================\n",
      "EVALUATING MODEL (Iteration 0)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de3ac5f0d65463a9d1e25624ffe3e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS\n",
      "================================================================================\n",
      "Accuracy: 0.6391 (843/1319)\n",
      "================================================================================\n",
      "ðŸ’¾ State saved to ./small_project/star/training_state.json\n",
      "\n",
      "Iteration 0 COMPLETE and checkpointed\n",
      "Checkpoint saved - safe to interrupt and resume\n",
      "\n",
      "================================================================================\n",
      "STaR TRAINING COMPLETE!\n",
      "================================================================================\n",
      "End time: 2025-10-12 20:17:28\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 13: Main STaR Training Loop with Checkpoint Resume ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING/RESUMING STaR TRAINING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Start/Resume time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "# Determine starting point\n",
    "start_iteration = checkpoint_manager.get_next_iteration()\n",
    "\n",
    "if start_iteration >= config.STAR_ITERATIONS:\n",
    "    print(f\"All {config.STAR_ITERATIONS} iterations already complete!\")\n",
    "    print(\"Loading final model for evaluation...\")\n",
    "else:\n",
    "    print(f\"Starting from iteration {start_iteration}\")\n",
    "    \n",
    "    # Load base model or last checkpoint\n",
    "    last_model_path = checkpoint_manager.get_last_model_path()\n",
    "    \n",
    "    if last_model_path and start_iteration > 0:\n",
    "        print(f\"Resuming from checkpoint: {last_model_path}\")\n",
    "        current_model = AutoModelForCausalLM.from_pretrained(\n",
    "            last_model_path,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "            use_cache=False\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Loading base model: {config.MODEL_NAME}\")\n",
    "        current_model = AutoModelForCausalLM.from_pretrained(\n",
    "            config.MODEL_NAME,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "            use_cache=False\n",
    "        )\n",
    "    \n",
    "    current_model.gradient_checkpointing_enable()\n",
    "    print(f\"Model loaded and ready\")\n",
    "    \n",
    "    # Run iterations\n",
    "    for iteration in range(start_iteration, config.STAR_ITERATIONS):\n",
    "        print(f\"\\n{'#'*80}\")\n",
    "        print(f\"# STaR ITERATION {iteration + 1}/{config.STAR_ITERATIONS}\")\n",
    "        print(f\"{'#'*80}\")\n",
    "        print(f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        \n",
    "        try:\n",
    "            # Generate STaR dataset\n",
    "            star_dataset, stats = generate_star_dataset(current_model, tokenizer, train_data, iteration)\n",
    "            \n",
    "            if len(star_dataset) == 0:\n",
    "                print(f\"\\nNo correct examples generated in iteration {iteration}. Stopping.\")\n",
    "                break\n",
    "            \n",
    "            # Train on STaR dataset\n",
    "            current_model = train_on_star_dataset(current_model, tokenizer, star_dataset, iteration)\n",
    "            \n",
    "            # Evaluate\n",
    "            accuracy, results = evaluate_model(current_model, tokenizer, test_data, f\"(Iteration {iteration})\")\n",
    "            \n",
    "            # Save iteration results\n",
    "            iter_dir = f\"{config.CHECKPOINT_DIR}/iteration_{iteration}\"\n",
    "            with open(f\"{iter_dir}/evaluation_results.json\", \"w\") as f:\n",
    "                json.dump({\n",
    "                    \"iteration\": iteration,\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"correct\": int(accuracy * len(test_data)),\n",
    "                    \"total\": len(test_data),\n",
    "                    \"detailed_results\": results\n",
    "                }, f, indent=2)\n",
    "            \n",
    "            # Mark iteration complete in checkpoint\n",
    "            checkpoint_manager.mark_iteration_complete(iteration, stats, accuracy)\n",
    "            \n",
    "            print(f\"\\nIteration {iteration} COMPLETE and checkpointed\")\n",
    "            print(f\"Checkpoint saved - safe to interrupt and resume\")\n",
    "            \n",
    "            # Clean up memory\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nERROR in iteration {iteration}: {str(e)}\")\n",
    "            print(\"State has been saved. You can resume from this point.\")\n",
    "            raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STaR TRAINING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0daca60-e360-40af-8acd-c9d37631f4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading final results...\n",
      "Loading final model from ./small_project/star/checkpoints/iteration_0/model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb347eb47704fb9bde7879d9bad76d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CELL 14: Load Final Model and Results ---\n",
    "print(\"\\nLoading final results...\")\n",
    "\n",
    "# Load final model\n",
    "final_model_path = checkpoint_manager.get_last_model_path()\n",
    "if final_model_path:\n",
    "    print(f\"Loading final model from {final_model_path}\")\n",
    "    final_model = AutoModelForCausalLM.from_pretrained(\n",
    "        final_model_path,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16,\n",
    "    )\n",
    "else:\n",
    "    print(\"No trained model found, using current model\")\n",
    "    final_model = current_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212007f4-4170-4a3f-be21-5ed60db7e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL EVALUATION ON TEST SET\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUATING MODEL (Final)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a6f73368f34263a0fdc9da7edfb4e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CELL 15: Final Evaluation ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL EVALUATION ON TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "final_accuracy, final_results = evaluate_model(final_model, tokenizer, test_data, \"(Final)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c62471-5283-4f9f-aeae-c507625c980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 16: Save Final Results ---\n",
    "print(\"\\nSaving final results...\")\n",
    "\n",
    "final_summary = {\n",
    "    \"experiment\": \"star\",\n",
    "    \"model\": config.MODEL_NAME,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"training_started\": checkpoint_manager.state.get(\"start_time\"),\n",
    "    \"training_completed\": datetime.now().isoformat(),\n",
    "    \"config\": {\n",
    "        \"train_size\": len(train_data),\n",
    "        \"test_size\": len(test_data),\n",
    "        \"star_iterations\": config.STAR_ITERATIONS,\n",
    "        \"completed_iterations\": len(checkpoint_manager.state[\"completed_iterations\"]),\n",
    "        \"epochs_per_iteration\": config.NUM_EPOCHS,\n",
    "        \"batch_size\": config.BATCH_SIZE,\n",
    "        \"learning_rate\": config.LEARNING_RATE,\n",
    "        \"gradient_accumulation_steps\": config.GRADIENT_ACCUMULATION_STEPS,\n",
    "    },\n",
    "    \"final_results\": {\n",
    "        \"accuracy\": float(final_accuracy),\n",
    "        \"correct\": int(final_accuracy * len(test_data)),\n",
    "        \"total\": len(test_data),\n",
    "    },\n",
    "    \"iteration_stats\": checkpoint_manager.state[\"all_stats\"],\n",
    "    \"accuracy_progression\": checkpoint_manager.state[\"all_accuracies\"],\n",
    "}\n",
    "\n",
    "with open(f\"{config.OUTPUT_DIR}/results_summary.json\", \"w\") as f:\n",
    "    json.dump(final_summary, f, indent=2)\n",
    "\n",
    "with open(f\"{config.OUTPUT_DIR}/detailed_results.json\", \"w\") as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(f\"âœ“ Results saved to:\")\n",
    "print(f\"  - {config.OUTPUT_DIR}/results_summary.json\")\n",
    "print(f\"  - {config.OUTPUT_DIR}/detailed_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386a153-37a3-4cc2-b2eb-033d95bdb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CELL 17: Visualizations ---\n",
    "print(\"\\nðŸ“ˆ Generating visualizations...\")\n",
    "\n",
    "if checkpoint_manager.state[\"all_stats\"]:\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: STaR Dataset Generation Progress\n",
    "    all_stats = checkpoint_manager.state[\"all_stats\"]\n",
    "    iterations = [s['iteration'] for s in all_stats]\n",
    "    correct_gen = [s['correct_without_hint'] for s in all_stats]\n",
    "    correct_rat = [s['correct_with_hint'] for s in all_stats]\n",
    "    failed = [s['failed'] for s in all_stats]\n",
    "    \n",
    "    x = np.arange(len(iterations))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax1.bar(x - width, correct_gen, width, label='Generated (no hint)', color='#2ecc71', alpha=0.8)\n",
    "    ax1.bar(x, correct_rat, width, label='Rationalized (with hint)', color='#3498db', alpha=0.8)\n",
    "    ax1.bar(x + width, failed, width, label='Failed', color='#e74c3c', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('STaR Iteration', fontweight='bold', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Examples', fontweight='bold', fontsize=12)\n",
    "    ax1.set_title('STaR Dataset Generation Progress', fontweight='bold', fontsize=14)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([f'Iter {i}' for i in iterations])\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for i in x:\n",
    "        total = correct_gen[i] + correct_rat[i] + failed[i]\n",
    "        success_pct = (correct_gen[i] + correct_rat[i]) / total * 100\n",
    "        ax1.text(i, correct_gen[i] + correct_rat[i] + 5, f'{success_pct:.1f}%', \n",
    "                ha='center', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Plot 2: Accuracy Progression\n",
    "    if checkpoint_manager.state[\"all_accuracies\"]:\n",
    "        all_accuracies = checkpoint_manager.state[\"all_accuracies\"]\n",
    "        iter_nums = [a['iteration'] for a in all_accuracies]\n",
    "        accuracies = [a['accuracy'] * 100 for a in all_accuracies]\n",
    "        \n",
    "        ax2.plot(iter_nums, accuracies, marker='o', linewidth=3, markersize=10, \n",
    "                color='#2ecc71', label='Test Accuracy')\n",
    "        ax2.set_xlabel('STaR Iteration', fontweight='bold', fontsize=12)\n",
    "        ax2.set_ylabel('Accuracy (%)', fontweight='bold', fontsize=12)\n",
    "        ax2.set_title('Test Accuracy Progression', fontweight='bold', fontsize=14)\n",
    "        ax2.set_xticks(iter_nums)\n",
    "        ax2.set_xticklabels([f'Iter {i}' for i in iter_nums])\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend(fontsize=10)\n",
    "        \n",
    "        # Annotate points\n",
    "        for i, (x_val, y_val) in enumerate(zip(iter_nums, accuracies)):\n",
    "            ax2.annotate(f'{y_val:.2f}%', (x_val, y_val), textcoords=\"offset points\",\n",
    "                        xytext=(0, 10), ha='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    # Plot 3: Success Rate by Method\n",
    "    gen_rates = [s['correct_without_hint'] / s['total'] * 100 for s in all_stats]\n",
    "    rat_rates = [s['correct_with_hint'] / s['total'] * 100 for s in all_stats]\n",
    "    \n",
    "    ax3.plot(iterations, gen_rates, marker='s', linewidth=2, markersize=8,\n",
    "            color='#2ecc71', label='Generation Success Rate', linestyle='--')\n",
    "    ax3.plot(iterations, rat_rates, marker='^', linewidth=2, markersize=8,\n",
    "            color='#3498db', label='Rationalization Success Rate', linestyle='--')\n",
    "    \n",
    "    ax3.set_xlabel('STaR Iteration', fontweight='bold', fontsize=12)\n",
    "    ax3.set_ylabel('Success Rate (%)', fontweight='bold', fontsize=12)\n",
    "    ax3.set_title('Success Rate by Method', fontweight='bold', fontsize=14)\n",
    "    ax3.set_xticks(iterations)\n",
    "    ax3.set_xticklabels([f'Iter {i}' for i in iterations])\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Cumulative Training Data\n",
    "    cumulative_data = []\n",
    "    cumulative = 0\n",
    "    for s in all_stats:\n",
    "        cumulative += s['correct_without_hint'] + s['correct_with_hint']\n",
    "        cumulative_data.append(cumulative)\n",
    "    \n",
    "    ax4.bar(iterations, cumulative_data, color='#9b59b6', alpha=0.8, edgecolor='black')\n",
    "    ax4.set_xlabel('STaR Iteration', fontweight='bold', fontsize=12)\n",
    "    ax4.set_ylabel('Cumulative Training Examples', fontweight='bold', fontsize=12)\n",
    "    ax4.set_title('Cumulative STaR Training Data', fontweight='bold', fontsize=14)\n",
    "    ax4.set_xticks(iterations)\n",
    "    ax4.set_xticklabels([f'Iter {i}' for i in iterations])\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (iter_num, cum) in enumerate(zip(iterations, cumulative_data)):\n",
    "        ax4.text(i, cum + max(cumulative_data)*0.02, str(cum),\n",
    "                ha='center', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{config.OUTPUT_DIR}/star_training_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"âœ“ Visualization saved to {config.OUTPUT_DIR}/star_training_analysis.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8032aec3-fc2f-4427-a211-d1611d8b5ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE FINAL PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "âœ“ CORRECT PREDICTIONS (showing up to 5):\n",
      "\n",
      "1. Q: Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for ...\n",
      "   Predicted: 18 | Correct: 18\n",
      "   Response: nsumed or used:** 3 + 4 = 7 eggs/day\n",
      "\n",
      "Now, let's subtract the total eggs consumed from the total number of eggs laid:\n",
      "**Eggs left for sale:** 16 - 7 = 9 eggs/day\n",
      "\n",
      "Since each egg is sold for $2, we mul...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Q: A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it ...\n",
      "   Predicted: 3 | Correct: 3\n",
      "   Response: us:\n",
      "2 x 1/2 = 1\n",
      "So, we need 1 bolt of white fiber.\n",
      "3. To find the total number of bolts needed, add the number of blue fibers (2) to the number of white fibers (1):\n",
      "2 + 1 = 3\n",
      "\n",
      "The final answer is: ###...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Q: James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meter...\n",
      "   Predicted: 540 | Correct: 540\n",
      "   Response: per sprint (60 meters):\n",
      "   3 x 60 = 180 meters per session\n",
      "3. Since James runs 3 sessions per week, we need to find out how much he runs in a whole week:\n",
      "   Multiply the distance per session (180 mete...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Q: Toulouse has twice as many sheep as Charleston. Charleston has 4 times as many sheep as Seattle. How...\n",
      "   Predicted: 260 | Correct: 260\n",
      "   Response: x 4 = 80\n",
      "3. Now we know Charleston has 80 sheep.\n",
      "4. Since Toulouse has twice as many sheep as Charleston, we multiply Charleston's number of sheep (80) by 2:\n",
      "   Toulouse = 80 x 2 = 160\n",
      "5. Finally, to ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Q: Eliza's rate per hour for the first 40 hours she works each week is $10. She also receives an overti...\n",
      "   Predicted: 460 | Correct: 460\n",
      "   Response: f overtime hours worked**\n",
      "Since Eliza worked a total of 45 hours, we subtract the regular hours from that to find out how many overtime hours were worked:\n",
      "Overtime hours = Total hours - Regular hours\n",
      "...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ— INCORRECT PREDICTIONS (showing up to 5):\n",
      "\n",
      "1. Q: Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repai...\n",
      "   Predicted: 195000 | Correct: 70000\n",
      "   Response: Calculate the new selling price**\n",
      "The value of the house increased by 150% due to the renovations.\n",
      "New selling price = Initial cost x (1 + 0.5) (since 150% is equivalent to multiplying by 250%)\n",
      "= $130...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Q: Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, meal...\n",
      "   Predicted: 40 | Correct: 20\n",
      "   Response: ince there are 20 chickens in the flock, we can divide the total amount of feed already given (40 cups) by the number of chickens (20) to find out how much each chicken should get: 40 Ã· 20 = 2 cups pe...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Q: Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second g...\n",
      "   Predicted: 50 | Correct: 64\n",
      "   Response: nal price ($3), we can calculate their total cost:\n",
      "   - Discounted glasses: 8 glasses x $3 = $24\n",
      "3. Now, let's add up the costs of both types of glasses:\n",
      "   - Total cost = Cost of regular glasses + Co...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "4. Q: Carla is downloading a 200 GB file. Normally she can download 2 GB/minute, but 40% of the way throug...\n",
      "   Predicted: 100 | Correct: 160\n",
      "   Response: e / Download rate\n",
      "= 200 GB / 2 GB/minute\n",
      "= 100 minutes\n",
      "\n",
      "**Step 2: Calculate the time spent downloading before the restart**\n",
      "Since 40% of the file is downloaded before the restart, we need to find out ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "5. Q: John drives for 3 hours at a speed of 60 mph and then turns around because he realizes he forgot som...\n",
      "   Predicted: 105 | Correct: 45\n",
      "   Response: le driving at 30 mph for half an hour.\n",
      "Distance = Speed x Time\n",
      "= 30 mph x 0.5 hours (since there are 60 minutes in an hour)\n",
      "= 15 miles\n",
      "\n",
      "\n",
      "## Step 3: Determine the remaining time John has to reach home ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 18: Sample Predictions ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE FINAL PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "correct_preds = [r for r in final_results if r['is_correct']][:5]\n",
    "incorrect_preds = [r for r in final_results if not r['is_correct']][:5]\n",
    "\n",
    "if correct_preds:\n",
    "    print(f\"\\nâœ“ CORRECT PREDICTIONS (showing up to 5):\")\n",
    "    for i, r in enumerate(correct_preds):\n",
    "        print(f\"\\n{i+1}. Q: {r['question'][:100]}...\")\n",
    "        print(f\"   Predicted: {r['predicted_answer']} | Correct: {r['correct_answer']}\")\n",
    "        print(f\"   Response: {r['response_preview']}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "if incorrect_preds:\n",
    "    print(f\"\\nâœ— INCORRECT PREDICTIONS (showing up to 5):\")\n",
    "    for i, r in enumerate(incorrect_preds):\n",
    "        print(f\"\\n{i+1}. Q: {r['question'][:100]}...\")\n",
    "        print(f\"   Predicted: {r['predicted_answer']} | Correct: {r['correct_answer']}\")\n",
    "        print(f\"   Response: {r['response_preview']}...\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4588e9c-f912-4504-a0a8-936ed4f8b03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STaR TRAINING SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STaR TRAINING COMPLETE - SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "EXPERIMENT CONFIGURATION\n",
      "================================================================================\n",
      "Model: meta-llama/Llama-3.2-3B-Instruct\n",
      "Training Dataset: 7473 examples\n",
      "Test Dataset: 1319 examples\n",
      "STaR Iterations: 1\n",
      "Completed Iterations: 1\n",
      "Epochs per Iteration: 2\n",
      "Batch Size: 4\n",
      "Gradient Accumulation: 4\n",
      "Effective Batch Size: 16\n",
      "Learning Rate: 2e-05\n",
      "\n",
      "TRAINING TIMELINE\n",
      "================================================================================\n",
      "Started: 2025-10-12T18:26:48.222281\n",
      "Completed: 2025-10-12T21:39:05.885057\n",
      "Completed Iterations: [0]\n",
      "\n",
      "DATASET GENERATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Iteration 0:\n",
      "  Total examples: 7473\n",
      "  Generated (no hint): 5095 (68.2%)\n",
      "  Rationalized (with hint): 1312 (17.6%)\n",
      "  Failed: 1066 (14.3%)\n",
      "  Success rate: 85.7%\n",
      "  Training examples: 6407\n",
      "\n",
      "================================================================================\n",
      "ACCURACY PROGRESSION\n",
      "================================================================================\n",
      "After Iteration 0: 0.6391 (843/1319)\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS\n",
      "================================================================================\n",
      "Final Test Accuracy: 0.6338\n",
      "Correct Predictions: 836/1319\n",
      "\n",
      "================================================================================\n",
      "FILES GENERATED\n",
      "================================================================================\n",
      "Main Results:\n",
      "  - ./small_project/star/results_summary.json\n",
      "  - ./small_project/star/detailed_results.json\n",
      "  - ./small_project/star/star_training_analysis.png\n",
      "\n",
      "Checkpoints:\n",
      "  - ./small_project/star/checkpoints/iteration_*/model/\n",
      "  - ./small_project/star/checkpoints/iteration_*/star_dataset.json\n",
      "  - ./small_project/star/checkpoints/iteration_*/generation_stats.json\n",
      "\n",
      "Training State:\n",
      "  - ./small_project/star/training_state.json\n",
      "\n",
      "================================================================================\n",
      "RESUMABILITY\n",
      "================================================================================\n",
      "This experiment used checkpoint-based resumable training.\n",
      "If interrupted, re-run all cells to resume from the last completed iteration.\n",
      "To restart from scratch, set Config.FORCE_RESTART = True\n",
      "\n",
      "================================================================================\n",
      "\n",
      "âœ“ Report saved to ./small_project/star/training_report.txt\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 19: Detailed Summary Report ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STaR TRAINING SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "report = f\"\"\"\n",
    "{'='*80}\n",
    "STaR TRAINING COMPLETE - SUMMARY REPORT\n",
    "{'='*80}\n",
    "\n",
    "EXPERIMENT CONFIGURATION\n",
    "{'='*80}\n",
    "Model: {config.MODEL_NAME}\n",
    "Training Dataset: {len(train_data)} examples\n",
    "Test Dataset: {len(test_data)} examples\n",
    "STaR Iterations: {config.STAR_ITERATIONS}\n",
    "Completed Iterations: {len(checkpoint_manager.state['completed_iterations'])}\n",
    "Epochs per Iteration: {config.NUM_EPOCHS}\n",
    "Batch Size: {config.BATCH_SIZE}\n",
    "Gradient Accumulation: {config.GRADIENT_ACCUMULATION_STEPS}\n",
    "Effective Batch Size: {config.BATCH_SIZE * config.GRADIENT_ACCUMULATION_STEPS}\n",
    "Learning Rate: {config.LEARNING_RATE}\n",
    "\n",
    "TRAINING TIMELINE\n",
    "{'='*80}\n",
    "Started: {checkpoint_manager.state.get('start_time', 'N/A')}\n",
    "Completed: {datetime.now().isoformat()}\n",
    "Completed Iterations: {checkpoint_manager.state.get('completed_iterations', [])}\n",
    "\n",
    "DATASET GENERATION SUMMARY\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "if checkpoint_manager.state[\"all_stats\"]:\n",
    "    for i, stat in enumerate(checkpoint_manager.state[\"all_stats\"]):\n",
    "        total = stat['total']\n",
    "        gen = stat['correct_without_hint']\n",
    "        rat = stat['correct_with_hint']\n",
    "        fail = stat['failed']\n",
    "        success_total = gen + rat\n",
    "        \n",
    "        report += f\"\"\"\n",
    "Iteration {i}:\n",
    "  Total examples: {total}\n",
    "  Generated (no hint): {gen} ({gen/total*100:.1f}%)\n",
    "  Rationalized (with hint): {rat} ({rat/total*100:.1f}%)\n",
    "  Failed: {fail} ({fail/total*100:.1f}%)\n",
    "  Success rate: {success_total/total*100:.1f}%\n",
    "  Training examples: {success_total}\n",
    "\"\"\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "ACCURACY PROGRESSION\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "if checkpoint_manager.state[\"all_accuracies\"]:\n",
    "    for acc_data in checkpoint_manager.state[\"all_accuracies\"]:\n",
    "        iter_num = acc_data['iteration']\n",
    "        acc = acc_data['accuracy']\n",
    "        correct = int(acc * len(test_data))\n",
    "        report += f\"After Iteration {iter_num}: {acc:.4f} ({correct}/{len(test_data)})\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "{'='*80}\n",
    "FINAL RESULTS\n",
    "{'='*80}\n",
    "Final Test Accuracy: {final_accuracy:.4f}\n",
    "Correct Predictions: {int(final_accuracy * len(test_data))}/{len(test_data)}\n",
    "\n",
    "{'='*80}\n",
    "FILES GENERATED\n",
    "{'='*80}\n",
    "Main Results:\n",
    "  - {config.OUTPUT_DIR}/results_summary.json\n",
    "  - {config.OUTPUT_DIR}/detailed_results.json\n",
    "  - {config.OUTPUT_DIR}/star_training_analysis.png\n",
    "\n",
    "Checkpoints:\n",
    "  - {config.CHECKPOINT_DIR}/iteration_*/model/\n",
    "  - {config.CHECKPOINT_DIR}/iteration_*/star_dataset.json\n",
    "  - {config.CHECKPOINT_DIR}/iteration_*/generation_stats.json\n",
    "\n",
    "Training State:\n",
    "  - {config.STATE_FILE}\n",
    "\n",
    "{'='*80}\n",
    "RESUMABILITY\n",
    "{'='*80}\n",
    "This experiment used checkpoint-based resumable training.\n",
    "If interrupted, re-run all cells to resume from the last completed iteration.\n",
    "To restart from scratch, set Config.FORCE_RESTART = True\n",
    "\n",
    "{'='*80}\n",
    "\"\"\"\n",
    "\n",
    "# Save report\n",
    "with open(f\"{config.OUTPUT_DIR}/training_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(report)\n",
    "print(f\"âœ“ Report saved to {config.OUTPUT_DIR}/training_report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3238e14-607b-4ff6-a005-67f8d0b7c0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ITERATION STATISTICS TABLE\n",
      "================================================================================\n",
      "\n",
      "Iter   Total    Generated    Rational.    Failed   Success%   Test Acc  \n",
      "--------------------------------------------------------------------------------\n",
      "0      7473     5095         1312         1066     85.7       0.6391    \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 20: Statistics Table ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ITERATION STATISTICS TABLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if checkpoint_manager.state[\"all_stats\"]:\n",
    "    # Create table\n",
    "    print(f\"\\n{'Iter':<6} {'Total':<8} {'Generated':<12} {'Rational.':<12} {'Failed':<8} {'Success%':<10} {'Test Acc':<10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, stat in enumerate(checkpoint_manager.state[\"all_stats\"]):\n",
    "        total = stat['total']\n",
    "        gen = stat['correct_without_hint']\n",
    "        rat = stat['correct_with_hint']\n",
    "        fail = stat['failed']\n",
    "        success_pct = (gen + rat) / total * 100\n",
    "        \n",
    "        # Get accuracy for this iteration if available\n",
    "        acc_data = next((a for a in checkpoint_manager.state[\"all_accuracies\"] if a['iteration'] == i), None)\n",
    "        test_acc = f\"{acc_data['accuracy']:.4f}\" if acc_data else \"N/A\"\n",
    "        \n",
    "        print(f\"{i:<6} {total:<8} {gen:<12} {rat:<12} {fail:<8} {success_pct:<10.1f} {test_acc:<10}\")\n",
    "    \n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18abb2a4-86d2-45d5-8f17-c1caeaafe5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PERFORMANCE METRICS\n",
      "================================================================================\n",
      "\n",
      "Average generation success rate: 68.18%\n",
      "Average rationalization success rate: 17.56%\n",
      "Average overall success rate: 85.74%\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 21: Performance Metrics ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if checkpoint_manager.state[\"all_accuracies\"] and len(checkpoint_manager.state[\"all_accuracies\"]) >= 2:\n",
    "    first_acc = checkpoint_manager.state[\"all_accuracies\"][0]['accuracy']\n",
    "    final_acc = checkpoint_manager.state[\"all_accuracies\"][-1]['accuracy']\n",
    "    improvement = (final_acc - first_acc) * 100\n",
    "    \n",
    "    print(f\"\\nFirst iteration accuracy: {first_acc:.4f}\")\n",
    "    print(f\"Final iteration accuracy: {final_acc:.4f}\")\n",
    "    print(f\"Absolute improvement: {improvement:+.2f}%\")\n",
    "    print(f\"Relative improvement: {(final_acc / first_acc - 1) * 100:+.2f}%\")\n",
    "\n",
    "# Calculate average success rates\n",
    "if checkpoint_manager.state[\"all_stats\"]:\n",
    "    avg_gen_rate = np.mean([s['correct_without_hint'] / s['total'] for s in checkpoint_manager.state[\"all_stats\"]])\n",
    "    avg_rat_rate = np.mean([s['correct_with_hint'] / s['total'] for s in checkpoint_manager.state[\"all_stats\"]])\n",
    "    avg_success_rate = np.mean([(s['correct_without_hint'] + s['correct_with_hint']) / s['total'] \n",
    "                                 for s in checkpoint_manager.state[\"all_stats\"]])\n",
    "    \n",
    "    print(f\"\\nAverage generation success rate: {avg_gen_rate*100:.2f}%\")\n",
    "    print(f\"Average rationalization success rate: {avg_rat_rate*100:.2f}%\")\n",
    "    print(f\"Average overall success rate: {avg_success_rate*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4492d835-07ec-4ecf-9324-d28120698c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CHECKPOINT INFORMATION\n",
      "================================================================================\n",
      "\n",
      "Checkpoint directory: ./small_project/star/checkpoints\n",
      "State file: ./small_project/star/training_state.json\n",
      "\n",
      "Completed iterations: [0]\n",
      "Last completed iteration: 0\n",
      "Iteration 0 checkpoint size: 25.75 GB\n",
      "\n",
      "Total checkpoint storage: 25.75 GB\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 22: Checkpoint Information ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CHECKPOINT INFORMATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nCheckpoint directory: {config.CHECKPOINT_DIR}\")\n",
    "print(f\"State file: {config.STATE_FILE}\")\n",
    "print(f\"\\nCompleted iterations: {checkpoint_manager.state.get('completed_iterations', [])}\")\n",
    "print(f\"Last completed iteration: {checkpoint_manager.state.get('last_completed_iteration', -1)}\")\n",
    "\n",
    "# Check checkpoint sizes\n",
    "total_checkpoint_size = 0\n",
    "for iter_num in checkpoint_manager.state.get('completed_iterations', []):\n",
    "    iter_dir = f\"{config.CHECKPOINT_DIR}/iteration_{iter_num}\"\n",
    "    if os.path.exists(iter_dir):\n",
    "        size = sum(os.path.getsize(os.path.join(dirpath, filename))\n",
    "                   for dirpath, dirnames, filenames in os.walk(iter_dir)\n",
    "                   for filename in filenames)\n",
    "        total_checkpoint_size += size\n",
    "        print(f\"Iteration {iter_num} checkpoint size: {size / 1e9:.2f} GB\")\n",
    "\n",
    "print(f\"\\nTotal checkpoint storage: {total_checkpoint_size / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1a35126-e722-4fe0-8c8a-27cfa65e4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸŽ‰ STaR EXPERIMENT COMPLETE!\n",
      "================================================================================\n",
      "\n",
      " Successfully completed 1 STaR iterations\n",
      " Final test accuracy: 0.6338\n",
      " All results saved to: ./small_project/star/\n",
      " Checkpoints saved for resumability\n",
      "\n",
      "KEY FILES:\n",
      "   ./small_project/star/results_summary.json - Main results\n",
      "   ./small_project/star/detailed_results.json - All predictions\n",
      "   ./small_project/star/training_report.txt - Full report\n",
      "   ./small_project/star/star_training_analysis.png - Visualizations\n",
      "   ./small_project/star/training_state.json - Training state (for resume)\n",
      "\n",
      "CHECKPOINT MODELS:\n",
      "\n",
      "  Iteration 0: ./small_project/star/checkpoints/iteration_0/model\n",
      "\n",
      "================================================================================\n",
      "TO RESUME TRAINING (if interrupted):\n",
      "  1. Keep Config.FORCE_RESTART = False\n",
      "  2. Re-run all cells\n",
      "  3. Training will resume from last checkpoint\n",
      "\n",
      "TO START FRESH:\n",
      "  1. Set Config.FORCE_RESTART = True\n",
      "  2. Re-run all cells\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Thank you for using the STaR training system! \n"
     ]
    }
   ],
   "source": [
    "# --- CELL 23: Final Summary ---\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ STaR EXPERIMENT COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    " Successfully completed {len(checkpoint_manager.state.get('completed_iterations', []))} STaR iterations\n",
    " Final test accuracy: {final_accuracy:.4f}\n",
    " All results saved to: {config.OUTPUT_DIR}/\n",
    " Checkpoints saved for resumability\n",
    "\n",
    "KEY FILES:\n",
    "   {config.OUTPUT_DIR}/results_summary.json - Main results\n",
    "   {config.OUTPUT_DIR}/detailed_results.json - All predictions\n",
    "   {config.OUTPUT_DIR}/training_report.txt - Full report\n",
    "   {config.OUTPUT_DIR}/star_training_analysis.png - Visualizations\n",
    "   {config.STATE_FILE} - Training state (for resume)\n",
    "\n",
    "CHECKPOINT MODELS:\n",
    "\"\"\")\n",
    "\n",
    "for iter_num in checkpoint_manager.state.get('completed_iterations', []):\n",
    "    model_path = f\"{config.CHECKPOINT_DIR}/iteration_{iter_num}/model\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"  Iteration {iter_num}: {model_path}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "{'='*80}\n",
    "TO RESUME TRAINING (if interrupted):\n",
    "  1. Keep Config.FORCE_RESTART = False\n",
    "  2. Re-run all cells\n",
    "  3. Training will resume from last checkpoint\n",
    "\n",
    "TO START FRESH:\n",
    "  1. Set Config.FORCE_RESTART = True\n",
    "  2. Re-run all cells\n",
    "\n",
    "{'='*80}\n",
    "\"\"\")\n",
    "\n",
    "print(\"Thank you for using the STaR training system! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413b409-9cd0-48d3-856f-78928cb32231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
