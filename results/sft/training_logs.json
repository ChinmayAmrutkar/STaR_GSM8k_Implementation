[
  {
    "step": 10,
    "epoch": 0.02140754616002141,
    "loss": 4.9364,
    "grad_norm": 988.0,
    "learning_rate": 1.9148936170212767e-06
  },
  {
    "step": 20,
    "epoch": 0.04281509232004282,
    "loss": 1.1736,
    "grad_norm": 7.25,
    "learning_rate": 4.042553191489362e-06
  },
  {
    "step": 30,
    "epoch": 0.06422263848006422,
    "loss": 0.5465,
    "grad_norm": 2.96875,
    "learning_rate": 6.170212765957447e-06
  },
  {
    "step": 40,
    "epoch": 0.08563018464008564,
    "loss": 0.3907,
    "grad_norm": 1.3984375,
    "learning_rate": 8.297872340425532e-06
  },
  {
    "step": 50,
    "epoch": 0.10703773080010703,
    "loss": 0.3657,
    "grad_norm": 1.1953125,
    "learning_rate": 1.0425531914893619e-05
  },
  {
    "step": 60,
    "epoch": 0.12844527696012845,
    "loss": 0.3584,
    "grad_norm": 1.3515625,
    "learning_rate": 1.2553191489361702e-05
  },
  {
    "step": 70,
    "epoch": 0.14985282312014986,
    "loss": 0.3101,
    "grad_norm": 1.9921875,
    "learning_rate": 1.4680851063829789e-05
  },
  {
    "step": 80,
    "epoch": 0.17126036928017127,
    "loss": 0.3212,
    "grad_norm": 1.546875,
    "learning_rate": 1.6808510638297873e-05
  },
  {
    "step": 90,
    "epoch": 0.19266791544019266,
    "loss": 0.3039,
    "grad_norm": 1.1015625,
    "learning_rate": 1.893617021276596e-05
  },
  {
    "step": 100,
    "epoch": 0.21407546160021407,
    "loss": 0.2979,
    "grad_norm": 0.9921875,
    "learning_rate": 1.9998259904917257e-05
  },
  {
    "step": 110,
    "epoch": 0.23548300776023548,
    "loss": 0.3017,
    "grad_norm": 1.171875,
    "learning_rate": 1.998434277756163e-05
  },
  {
    "step": 120,
    "epoch": 0.2568905539202569,
    "loss": 0.2942,
    "grad_norm": 1.09375,
    "learning_rate": 1.9956527894864662e-05
  },
  {
    "step": 130,
    "epoch": 0.2782981000802783,
    "loss": 0.3142,
    "grad_norm": 1.1015625,
    "learning_rate": 1.9914853973889988e-05
  },
  {
    "step": 140,
    "epoch": 0.2997056462402997,
    "loss": 0.2951,
    "grad_norm": 0.91796875,
    "learning_rate": 1.985937902285815e-05
  },
  {
    "step": 150,
    "epoch": 0.3211131924003211,
    "loss": 0.295,
    "grad_norm": 0.94921875,
    "learning_rate": 1.9790180260401778e-05
  },
  {
    "step": 160,
    "epoch": 0.34252073856034254,
    "loss": 0.2875,
    "grad_norm": 1.09375,
    "learning_rate": 1.9707354008080736e-05
  },
  {
    "step": 170,
    "epoch": 0.3639282847203639,
    "loss": 0.3003,
    "grad_norm": 1.0625,
    "learning_rate": 1.9611015556306845e-05
  },
  {
    "step": 180,
    "epoch": 0.3853358308803853,
    "loss": 0.2891,
    "grad_norm": 1.0703125,
    "learning_rate": 1.9501299003864828e-05
  },
  {
    "step": 190,
    "epoch": 0.40674337704040675,
    "loss": 0.2867,
    "grad_norm": 0.9765625,
    "learning_rate": 1.937835707125284e-05
  },
  {
    "step": 200,
    "epoch": 0.42815092320042814,
    "loss": 0.3019,
    "grad_norm": 0.97265625,
    "learning_rate": 1.924236088810241e-05
  },
  {
    "step": 210,
    "epoch": 0.4495584693604496,
    "loss": 0.295,
    "grad_norm": 1.09375,
    "learning_rate": 1.909349975497372e-05
  },
  {
    "step": 220,
    "epoch": 0.47096601552047096,
    "loss": 0.2876,
    "grad_norm": 0.94921875,
    "learning_rate": 1.8931980879857737e-05
  },
  {
    "step": 230,
    "epoch": 0.4923735616804924,
    "loss": 0.3068,
    "grad_norm": 1.0859375,
    "learning_rate": 1.8758029089752023e-05
  },
  {
    "step": 240,
    "epoch": 0.5137811078405138,
    "loss": 0.2943,
    "grad_norm": 0.91015625,
    "learning_rate": 1.85718865177117e-05
  },
  {
    "step": 250,
    "epoch": 0.5351886540005352,
    "loss": 0.2977,
    "grad_norm": 0.86328125,
    "learning_rate": 1.8373812265811126e-05
  },
  {
    "step": 260,
    "epoch": 0.5565962001605566,
    "loss": 0.2922,
    "grad_norm": 0.9375,
    "learning_rate": 1.81640820444855e-05
  },
  {
    "step": 270,
    "epoch": 0.578003746320578,
    "loss": 0.2819,
    "grad_norm": 0.92578125,
    "learning_rate": 1.7942987788754348e-05
  },
  {
    "step": 280,
    "epoch": 0.5994112924805994,
    "loss": 0.2747,
    "grad_norm": 0.91796875,
    "learning_rate": 1.771083725186111e-05
  },
  {
    "step": 290,
    "epoch": 0.6208188386406208,
    "loss": 0.2922,
    "grad_norm": 0.98828125,
    "learning_rate": 1.746795357689453e-05
  },
  {
    "step": 300,
    "epoch": 0.6422263848006422,
    "loss": 0.2957,
    "grad_norm": 0.86328125,
    "learning_rate": 1.7214674846987992e-05
  },
  {
    "step": 310,
    "epoch": 0.6636339309606636,
    "loss": 0.2937,
    "grad_norm": 0.921875,
    "learning_rate": 1.695135361472305e-05
  },
  {
    "step": 320,
    "epoch": 0.6850414771206851,
    "loss": 0.2851,
    "grad_norm": 0.9375,
    "learning_rate": 1.6678356411392135e-05
  },
  {
    "step": 330,
    "epoch": 0.7064490232807065,
    "loss": 0.2756,
    "grad_norm": 0.9375,
    "learning_rate": 1.6396063236803465e-05
  },
  {
    "step": 340,
    "epoch": 0.7278565694407279,
    "loss": 0.2913,
    "grad_norm": 0.8984375,
    "learning_rate": 1.610486703033847e-05
  },
  {
    "step": 350,
    "epoch": 0.7492641156007492,
    "loss": 0.2761,
    "grad_norm": 0.9140625,
    "learning_rate": 1.5805173123997856e-05
  },
  {
    "step": 360,
    "epoch": 0.7706716617607706,
    "loss": 0.2876,
    "grad_norm": 0.9765625,
    "learning_rate": 1.549739867819773e-05
  },
  {
    "step": 370,
    "epoch": 0.7920792079207921,
    "loss": 0.3071,
    "grad_norm": 1.0078125,
    "learning_rate": 1.5181972101101083e-05
  },
  {
    "step": 380,
    "epoch": 0.8134867540808135,
    "loss": 0.2975,
    "grad_norm": 1.078125,
    "learning_rate": 1.4859332452292937e-05
  },
  {
    "step": 390,
    "epoch": 0.8348943002408349,
    "loss": 0.2956,
    "grad_norm": 0.921875,
    "learning_rate": 1.4529928831629185e-05
  },
  {
    "step": 400,
    "epoch": 0.8563018464008563,
    "loss": 0.2849,
    "grad_norm": 1.1015625,
    "learning_rate": 1.4194219754109812e-05
  },
  {
    "step": 410,
    "epoch": 0.8777093925608777,
    "loss": 0.3007,
    "grad_norm": 1.03125,
    "learning_rate": 1.3852672511646683e-05
  },
  {
    "step": 420,
    "epoch": 0.8991169387208992,
    "loss": 0.2924,
    "grad_norm": 0.98046875,
    "learning_rate": 1.350576252261425e-05
  },
  {
    "step": 430,
    "epoch": 0.9205244848809205,
    "loss": 0.2828,
    "grad_norm": 0.984375,
    "learning_rate": 1.3153972670088584e-05
  },
  {
    "step": 440,
    "epoch": 0.9419320310409419,
    "loss": 0.2834,
    "grad_norm": 0.9921875,
    "learning_rate": 1.2797792629695909e-05
  },
  {
    "step": 450,
    "epoch": 0.9633395772009633,
    "loss": 0.2912,
    "grad_norm": 0.875,
    "learning_rate": 1.2437718188006165e-05
  },
  {
    "step": 460,
    "epoch": 0.9847471233609848,
    "loss": 0.2923,
    "grad_norm": 1.03125,
    "learning_rate": 1.2074250552420459e-05
  },
  {
    "step": 470,
    "epoch": 1.0042815092320043,
    "loss": 0.2728,
    "grad_norm": 0.87109375,
    "learning_rate": 1.170789565351293e-05
  },
  {
    "step": 480,
    "epoch": 1.0256890553920257,
    "loss": 0.2554,
    "grad_norm": 0.890625,
    "learning_rate": 1.1339163440798187e-05
  },
  {
    "step": 490,
    "epoch": 1.047096601552047,
    "loss": 0.2537,
    "grad_norm": 0.93359375,
    "learning_rate": 1.0968567172904558e-05
  },
  {
    "step": 500,
    "epoch": 1.0685041477120685,
    "loss": 0.2454,
    "grad_norm": 0.984375,
    "learning_rate": 1.0596622703141209e-05
  },
  {
    "step": 510,
    "epoch": 1.0899116938720899,
    "loss": 0.2602,
    "grad_norm": 0.953125,
    "learning_rate": 1.0223847761453558e-05
  },
  {
    "step": 520,
    "epoch": 1.1113192400321112,
    "loss": 0.251,
    "grad_norm": 1.0859375,
    "learning_rate": 9.850761233766537e-06
  },
  {
    "step": 530,
    "epoch": 1.1327267861921326,
    "loss": 0.2532,
    "grad_norm": 1.3984375,
    "learning_rate": 9.47788243971875e-06
  },
  {
    "step": 540,
    "epoch": 1.1541343323521542,
    "loss": 0.2487,
    "grad_norm": 0.9765625,
    "learning_rate": 9.10573040979294e-06
  },
  {
    "step": 550,
    "epoch": 1.1755418785121756,
    "loss": 0.2297,
    "grad_norm": 0.93359375,
    "learning_rate": 8.734823162848919e-06
  },
  {
    "step": 560,
    "epoch": 1.196949424672197,
    "loss": 0.2598,
    "grad_norm": 1.046875,
    "learning_rate": 8.365676985064684e-06
  },
  {
    "step": 570,
    "epoch": 1.2183569708322184,
    "loss": 0.2479,
    "grad_norm": 1.0546875,
    "learning_rate": 7.998805711289281e-06
  },
  {
    "step": 580,
    "epoch": 1.2397645169922398,
    "loss": 0.2407,
    "grad_norm": 0.984375,
    "learning_rate": 7.634720009807879e-06
  },
  {
    "step": 590,
    "epoch": 1.2611720631522612,
    "loss": 0.2455,
    "grad_norm": 0.98046875,
    "learning_rate": 7.273926671514503e-06
  },
  {
    "step": 600,
    "epoch": 1.2825796093122825,
    "loss": 0.2337,
    "grad_norm": 1.078125,
    "learning_rate": 6.916927904481934e-06
  },
  {
    "step": 610,
    "epoch": 1.303987155472304,
    "loss": 0.2361,
    "grad_norm": 0.97265625,
    "learning_rate": 6.56422063491072e-06
  },
  {
    "step": 620,
    "epoch": 1.3253947016323253,
    "loss": 0.2373,
    "grad_norm": 1.0234375,
    "learning_rate": 6.216295815430277e-06
  },
  {
    "step": 630,
    "epoch": 1.346802247792347,
    "loss": 0.2404,
    "grad_norm": 0.92578125,
    "learning_rate": 5.873637741714941e-06
  },
  {
    "step": 640,
    "epoch": 1.368209793952368,
    "loss": 0.2358,
    "grad_norm": 0.8671875,
    "learning_rate": 5.536723378366226e-06
  },
  {
    "step": 650,
    "epoch": 1.3896173401123897,
    "loss": 0.2325,
    "grad_norm": 1.0,
    "learning_rate": 5.206021694999571e-06
  },
  {
    "step": 660,
    "epoch": 1.411024886272411,
    "loss": 0.2395,
    "grad_norm": 1.0546875,
    "learning_rate": 4.881993013459762e-06
  },
  {
    "step": 670,
    "epoch": 1.4324324324324325,
    "loss": 0.2498,
    "grad_norm": 0.89453125,
    "learning_rate": 4.565088367073675e-06
  },
  {
    "step": 680,
    "epoch": 1.4538399785924538,
    "loss": 0.2426,
    "grad_norm": 1.0234375,
    "learning_rate": 4.255748872832201e-06
  },
  {
    "step": 690,
    "epoch": 1.4752475247524752,
    "loss": 0.2382,
    "grad_norm": 1.1015625,
    "learning_rate": 3.9544051173752504e-06
  },
  {
    "step": 700,
    "epoch": 1.4966550709124966,
    "loss": 0.2528,
    "grad_norm": 1.0390625,
    "learning_rate": 3.6614765576345755e-06
  },
  {
    "step": 710,
    "epoch": 1.518062617072518,
    "loss": 0.2429,
    "grad_norm": 1.015625,
    "learning_rate": 3.3773709369685924e-06
  },
  {
    "step": 720,
    "epoch": 1.5394701632325396,
    "loss": 0.24,
    "grad_norm": 1.0234375,
    "learning_rate": 3.1024837176020173e-06
  },
  {
    "step": 730,
    "epoch": 1.5608777093925608,
    "loss": 0.2514,
    "grad_norm": 1.0625,
    "learning_rate": 2.8371975301602572e-06
  },
  {
    "step": 740,
    "epoch": 1.5822852555525824,
    "loss": 0.2542,
    "grad_norm": 1.09375,
    "learning_rate": 2.581881641064806e-06
  },
  {
    "step": 750,
    "epoch": 1.6036928017126035,
    "loss": 0.2321,
    "grad_norm": 1.0,
    "learning_rate": 2.3368914385310415e-06
  },
  {
    "step": 760,
    "epoch": 1.6251003478726251,
    "loss": 0.2342,
    "grad_norm": 0.95703125,
    "learning_rate": 2.1025679378838247e-06
  },
  {
    "step": 770,
    "epoch": 1.6465078940326465,
    "loss": 0.26,
    "grad_norm": 1.0625,
    "learning_rate": 1.8792373068795422e-06
  },
  {
    "step": 780,
    "epoch": 1.667915440192668,
    "loss": 0.2443,
    "grad_norm": 1.1484375,
    "learning_rate": 1.6672104116952748e-06
  },
  {
    "step": 790,
    "epoch": 1.6893229863526893,
    "loss": 0.2445,
    "grad_norm": 0.9609375,
    "learning_rate": 1.4667823842170837e-06
  },
  {
    "step": 800,
    "epoch": 1.7107305325127107,
    "loss": 0.2424,
    "grad_norm": 0.99609375,
    "learning_rate": 1.2782322112297274e-06
  },
  {
    "step": 810,
    "epoch": 1.7321380786727323,
    "loss": 0.2461,
    "grad_norm": 0.8984375,
    "learning_rate": 1.101822346079625e-06
  },
  {
    "step": 820,
    "epoch": 1.7535456248327534,
    "loss": 0.2326,
    "grad_norm": 1.078125,
    "learning_rate": 9.377983433516181e-07
  },
  {
    "step": 830,
    "epoch": 1.774953170992775,
    "loss": 0.2362,
    "grad_norm": 1.015625,
    "learning_rate": 7.863885170680486e-07
  },
  {
    "step": 840,
    "epoch": 1.7963607171527962,
    "loss": 0.2589,
    "grad_norm": 1.03125,
    "learning_rate": 6.478036228859363e-07
  },
  {
    "step": 850,
    "epoch": 1.8177682633128178,
    "loss": 0.2437,
    "grad_norm": 1.125,
    "learning_rate": 5.222365647345862e-07
  },
  {
    "step": 860,
    "epoch": 1.8391758094728392,
    "loss": 0.2556,
    "grad_norm": 1.125,
    "learning_rate": 4.0986212630201974e-07
  },
  {
    "step": 870,
    "epoch": 1.8605833556328606,
    "loss": 0.2254,
    "grad_norm": 1.109375,
    "learning_rate": 3.1083672774395055e-07
  },
  {
    "step": 880,
    "epoch": 1.881990901792882,
    "loss": 0.2467,
    "grad_norm": 1.0,
    "learning_rate": 2.2529820795397228e-07
  },
  {
    "step": 890,
    "epoch": 1.9033984479529034,
    "loss": 0.256,
    "grad_norm": 1.109375,
    "learning_rate": 1.5336563269803372e-07
  },
  {
    "step": 900,
    "epoch": 1.924805994112925,
    "loss": 0.2566,
    "grad_norm": 1.125,
    "learning_rate": 9.513912888025611e-08
  },
  {
    "step": 910,
    "epoch": 1.9462135402729461,
    "loss": 0.2521,
    "grad_norm": 1.125,
    "learning_rate": 5.0699745170785796e-08
  },
  {
    "step": 920,
    "epoch": 1.9676210864329677,
    "loss": 0.2352,
    "grad_norm": 0.984375,
    "learning_rate": 2.010933918970781e-08
  },
  {
    "step": 930,
    "epoch": 1.989028632592989,
    "loss": 0.2512,
    "grad_norm": 1.0234375,
    "learning_rate": 3.410491404017835e-09
  },
  {
    "step": 936,
    "epoch": 2.0,
    "train_runtime": 3051.0373,
    "train_samples_per_second": 4.899,
    "train_steps_per_second": 0.307,
    "total_flos": 1.294202834559959e+17,
    "train_loss": 0.3333522355199879
  }
]